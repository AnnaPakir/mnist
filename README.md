# Реализация метода обратного распространения ошибки для двухслойной полностью связанной нейронной сети 
Данный проект состоит из следующих этапов:

1. Вывод математических формул для вычисления градиентов функции ошибки по параметрам нейронной сети и формул коррекции весов. Используется метод обратного распространения ошибки.
2. Проектирование и разработка программной реализации нейронной сети, состоящей из одного скрытого слоя, на основе выведенных формул. Тестирование разработанной программной реализации.
3. Подготовка отчета по предыдущим пунктам.
4. Разработка такого же когда на библиотеке Keras
5. Разработка приложения, с использованием библиотеки gradio.

![plot](https://github.com/AnnaPakir/mnist/blob/main/mnist.gif)

Проект сделан на попульрном наборе даных - mnist.

![plot](https://github.com/AnnaPakir/mnist/blob/main/mnist.png)

В ходе проекта были выведены математические формулы для реализации нейронной сети. 

![plot](https://github.com/AnnaPakir/mnist/blob/main/form.png)

Дааные формулы были реализованы на языке Python  и протестированы с различными входными данными.

![plot](https://github.com/AnnaPakir/mnist/blob/main/loss.png)

Была создана похожая модель с помощью библиотеки Keras, протестирована на случайном примере.

![plot](https://github.com/AnnaPakir/mnist/blob/main/keras.png)

***
## Воспроизведение кода

Если есть желание вопроизвести блок с выводом формул, необходимо дополнительно установить библиотеку Latex 

```python
# Установим LaTeX
!apt-get update
!apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng cm-super
```
Для повторения экспериментов в библиотеке gratio ее также необходимо установить.

```python
!pip install gradio -q
```
Перед запуском блокнота также рекомендуется сверить версии библиотек, указанных в файле requirements.txt [link](https://github.com/AnnaPakir/mnist/blob/main/requirements.txt)



